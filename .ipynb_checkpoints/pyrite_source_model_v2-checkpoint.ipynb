{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyrite Source Model\n",
    "\n",
    "This notebook contains the code for modelling pyrite sources.\n",
    "\n",
    "The code is contained in this notebook, below, and it provides for training and saving a model, given some input chemical data along with sources, or predicting sources, just given the chemical data. \n",
    "\n",
    "The code implements 2 types of model:\n",
    "1. a linear, [Logistic Regression](https://en.wikipedia.org/wiki/Logistic_regression) model\n",
    "2. a non-linear, \"tree\" [Random Forest](https://en.wikipedia.org/wiki/Random_forest) model\n",
    "\n",
    "\n",
    "When you train a model it will output to the screen the score of the model, the percentage of predictions it gets right. The Logistic Regression model scores ~88% (there's a random element to the scores, you won't get the same thing every time), the Random Forest is better, scoring ~96%. The Logistic Regression model has the benefit of being easier to interpret, as explained below.  \n",
    "\n",
    "The linear model is the default. In both cases I've trained a model already, and they are in the **artifacts** folder, they are called ```model_linear.pkl``` and ```model_tree.pkl```. If an **artifacts** folder doesn't exist the code will make one.\n",
    "\n",
    "When you train a model this also creates a *feature importances* file in the **artifacts** folder. Again, I've already trained one model of each so these files are in the folder.\n",
    "\n",
    "---\n",
    "\n",
    "## Feature Importances\n",
    "\n",
    "These files contain the information on how the model uses the input to predict the Source.\n",
    "\n",
    "**feature_importances_linear.csv**: This file has a row for each Source, and a column for each of the features it uses to make the predictions. You can easily interpret these values, for a given row the value for a given chemical tells you how this chemical changes the prediction. \n",
    "\n",
    "For example, for Source A and Fe we have the value, -2.643681213392997. This means that increasing the amount of Fe decreases the likelihood that a given sample comes from Source A. For Source A and S we have, 3.953436861312359. This means that increasing the amount of S increases the probability that a sample comes from Source A, and it has a larger effect than Fe (since the absolute value is greater).\n",
    "\n",
    "**feature_importances_tree.csv**: This file has a row and a value for each chemical. These values are less easy to interpret, all we can say is that the larger the absolute value, the more important that chemical is in making the prediction, i.e. the stronger the relationship between this chemical and Source.\n",
    "\n",
    "---\n",
    "\n",
    "## Inputs and Outputs\n",
    "\n",
    "To train a model the code expects input in a csv file (formatted like the one in the **train** folder). It should have a column called *Source*, and it will try to learn to predict this using the other columns. It requires the other columns to be called:\n",
    "\n",
    "Fe, S, Co, Cu, Zn, As, Se, Mo, Ag, Sb, Pb, Stoichiometry\n",
    "\n",
    "To make a prediction it expects all of the columns above, except **Source**, in a file formatted like the training file. It will output a file called **output.csv**, which is exactly the same as the input file but with an added column called **Prediction**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use\n",
    "\n",
    "To train a model (which I've already done on the data you've provided, you won't need to redo this unless you're using new data), set ```mode``` (in the cell below) equal to 'train'. For predicting, set it to 'predict'.\n",
    "\n",
    "Next decide what kind of model (as described above) you want to train/predict with. For Logistic Regresion set ```model_type``` equal to 'linear', for the Random Forest model set it to 'tree'. \n",
    "\n",
    "Finally add the location of the data that you want to train/predict with, set ```filename``` to this path. By path I mean the **full** fodler and filename of the data you want to use, something like: 'C:\\Windows\\User\\Desktop\\train.csv'. (I've set it to 'train/train.csv', this works on my machine but will **not** work on yours. 'train\\train.csv' might, but the best bet is to go to the file and click on it, I think that shows the full path)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'train'\n",
    "model_type = 'tree'\n",
    "filename = r\"C:\\Users\\dorna\\Documents\\Trace element paper\\Modelling\\Train and test\\SisotopesAdded.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code, you shouldn't need to edit any of this. To run the model just go to *Cell* in the menu bar, and select *Run all*. The results will appear at the bottom, along with the output information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pickle\n",
    "import warnings\n",
    "import argparse\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "feats = ['Sisotopes', 'Fe', 'S', 'Co', 'Cu', 'Zn', 'As', 'Se', 'Mo', 'Ag', 'Sb', 'Pb']\n",
    "\n",
    "target = [\"Source\"]\n",
    "\n",
    "def read(fname, cols):\n",
    "    df = pd.read_csv(fname)\n",
    "    assert all(c in df.columns for c in cols), \\\n",
    "        f\"Not all columns found, all of {cols} needed for training\"\n",
    "\n",
    "    return df\n",
    "\n",
    "def make_pipe(kind):\n",
    "    assert kind is \"tree\" or kind is \"linear\", \\\n",
    "            f\"--kind must be tree or linear, got {kind}\"\n",
    "    if kind is \"linear\":\n",
    "        clf = (\"clf\", LogisticRegression())\n",
    "    elif kind is \"tree\":\n",
    "        clf = (\"clf\", ExtraTreeClassifier())\n",
    "\n",
    "    pipe = Pipeline([(\"Scaler\", StandardScaler()), clf])\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def train(df, kind):\n",
    "    pipe = make_pipe(kind)\n",
    "    pipe.fit(df[feats], df[target])\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def evaluate(df, model):\n",
    "    scores = cross_val_score(model, df[feats], df[target],\n",
    "            scoring=\"accuracy\", cv=10)\n",
    "    print(f\"The average score on 10-fold CV was {100*scores.mean():.2f}%\")\n",
    "\n",
    "def make_dir():\n",
    "    if 'artifacts' not in os.listdir():\n",
    "        os.mkdir('artifacts')\n",
    "    \n",
    "def full_train(fname, kind):\n",
    "    df = read(fname, target + feats)\n",
    "    model = train(df, kind)\n",
    "    pickle.dump(model, open(f\"artifacts/model_{kind}.pkl\", \"wb\"))\n",
    "    evaluate(df, model)\n",
    "    \n",
    "    make_dir()\n",
    "    with open(f\"artifacts/feature_importances_{kind}.csv\", \"w\") as f:\n",
    "        if kind is \"tree\":\n",
    "            imp = model.steps[1][1].feature_importances_\n",
    "            for i, c in zip(imp, feats):\n",
    "                f.write(f\"{c}, {i}\\n\")\n",
    "\n",
    "        else:\n",
    "            imp = model.steps[1][1].coef_\n",
    "            f.write(f\"{','.join(c for c in target + feats)}\\n\")\n",
    "            for name, row in zip(model.classes_, imp):\n",
    "                f.write(f\"{name}, {','.join([str(r) for r in row])}\\n\")\n",
    "\n",
    "\n",
    "def predict(fname, kind):\n",
    "    model = pickle.load(open(f\"artifacts/model_{kind}.pkl\", \"rb\"))\n",
    "    df = read(fname, feats)\n",
    "    df[\"Prediction\"] = model.predict(df[feats])\n",
    "    df[[f\"Probability_{n}\" for n in model.classes_]] = pd.DataFrame(model.predict_proba(df[feats]))\n",
    "\n",
    "    df.to_csv(\"output.csv\", index=False)\n",
    "    print(f'Prediction complete, model predictions saved to {os.getcwd() + \"/output.csv\"}')                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode is 'predict':\n",
    "    predict(filename, model_type)\n",
    "elif mode is 'train':\n",
    "    full_train(filename, model_type)\n",
    "else:\n",
    "    print(f\"mode must be 'train' or predict, it was set to {mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
